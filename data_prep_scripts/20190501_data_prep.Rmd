---
title: "Data prep for food hackathon"
author: "Catalina Moreno"
date: '`r format(Sys.time(), format = "%B %d, %Y")`'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE,
                      comment = NA)
library(tidyverse)
library(googlesheets)
```

## Background

Prepare data for PFC hackathon according to the following data model:


```{r, data_model}
## read in data model from google sheets
# gs_auth(new_user = TRUE) #auth account (one time action)
data_mod <- gs_read(gs_title("fields_and_descriptions"))

dat_mod_col_names <- data_mod %>% pull(field)

dat_mod_col_names
```

**Note:** 

* added open_time1 and open_time2 etc to data model on Google Drive for sites that have morning and afternoon open times

* Recommend to wait to assign UID until all compiled, then check name and address -- this is unique key

* What is long term ETL? How will pull future data, from shared drive or putting into db?

```{r, prep_future_ready_tables}
## create empty dataframe according todatamodel
dat1 <- data.frame(matrix(ncol = length(dat_mod_col_names), nrow = 0))
colnames(dat1) <- dat_mod_col_names
```

## data-conveniencesupermarkets

```{r, convenience_1}
data_convenience <- gs_read(gs_title("data-conveniencesupermarkets"))
head(data_convenience)

## very last row is all NA
data_convenience <- data_convenience %>% filter(!`Client ID` %in% "200310290007")
```

```{r, convenience_2}
## map data_convenience to dat1
data_convenience <- dat1 %>% 
  bind_rows(data_convenience %>% 
              mutate(address = ifelse(is.na(`Street #`), 
                                      `Street Name`, paste(`Street #`, `Street Name`))) %>% 
              select(name = Name,
                     type = Category,
                     address, 
                     state = State, 
                     zip_code = Zip, 
                     latitude = Lat, 
                     longitude = Lon)) #%>%  ## don't know day of operation yet, leave all NA
  #mutate_at(vars(contains("day")), ~replace(., is.na(.), 0))

head(data_convenience)
## write out as .csv 
write_excel_csv(data_convenience, "data_convenience_cleaned.csv")
```

**Missing information on hours/days of operation as well as SNAP, WIC, FMNP, fresh_produce-healthy, MRFEI_score info.**

## Allegheny_County_Farmers_Markets_Locations_2017

```{r, agh_farmers_market_1}
agh_farm_markets <- gs_read(gs_title("Allegheny_County_Farmers_Markets_Locations_2017"))
head(agh_farm_markets)
```

From `Day_Time` variable, need to be able to extract weekday(s), time of day open, months open. Write functions to extract this info (note these could be improved and will require further testing/updates):

```{r, agh_farmers_market_2}
source("support_funs.R")
## process and augment weekdays for each row of dataset 
multi_day_info <- vector("list", length = nrow(agh_farm_markets))

for(i in 1:nrow(agh_farm_markets)) {
  multi_day_info[[i]] <- weekday_calc(agh_farm_markets$Day_Time[i]) %>% 
    mutate(FID = agh_farm_markets$FID[i]) ## for join later
}


multi_day_info <- bind_rows(multi_day_info)

## go wide, to match data model:
multi_day_info <- multi_day_info %>% select(weekday, FID) %>% mutate(value = 1) %>% tidyr::spread(key = "weekday", value = "value") %>% mutate_at(vars(contains("day")), ~replace(., is.na(.), 0))

```

```{r, agh_farmers_market_3}
## using open time, month functions and left join wide weekday above into one dataframe that fits data model:
agh_farm_markets <- dat1 %>% 
  bind_rows(agh_farm_markets %>% 
              left_join(multi_day_info, by = "FID") %>% 
              rowwise() %>% 
              mutate(type = "Farmers Market",
                     weekday_val = str_trim(str_extract(Day_Time, "^[:alpha:]* ")),
                     open_time1 = time_calc(Day_Time)$open_time,
                     close_time1 = time_calc(Day_Time)$close_time,
                     date_from = season_calc(Season)$date_from,
                     date_to = season_calc(Season)$date_to) %>% ## this may not be robust
              select(type, open_time1, close_time1, date_from, date_to,
                     Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday,
                address = Address,
                     name = Name, ## ? is this the correct farmers market name??
                     city = City,
                     state = State, 
                     zip_code = Zip, 
                     location_description = Location__,
                     latitude = Y, 
                     longitude = X)) 

## check
head(agh_farm_markets)
```

```{r}
## fix green grocer entries to be of format Green Grocer (name of establishment)
agh_farm_markets <- agh_farm_markets %>% 
  rowwise() %>% 
  mutate(name = ifelse(str_detect(name, "Green Grocer"),
                                          paste0("Green Grocer (", str_split(str_replace_all(name, "â€™", ""), "[:punct:]")[[1]][1], ")"), name))
```

```{r}
## write out as .csv 
write_excel_csv(agh_farm_markets, "agh_farm_markets_cleaned.csv")
```

**Missing SNAP, WIC, FMNP, fresh_produce-healthy, MRFEI_score info.**

If Green Grocer -- process name such that "Green Grocer (Store Name Here)

## growpghgardens201712

```{r, readin3}
growpgh <- gs_read(gs_title("growpghgardens201712_readin"))
head(growpgh)
```

```{r, growpgh}
growpgh <- dat1 %>% 
  bind_rows(growpgh %>% 
              mutate(type = "Grow PGH Garden") %>% ## avoid their overly descript category field to simply types for merged dataset
              select(name = urban_grower,
                               type, 
                               address = street_address,
                               city,
                               state,
                               zip_code,
                               latitude, 
                               longitude
                               ))

## write out as .csv 
write_excel_csv(growpgh, "growpghgardens_cleaned.csv")
```


**check addresses (not necessarily a street address), want to filter city to == Pittsburgh? Missing open day/time, SNAP etc info**

## PA

```{r, readinpa}
PA <- gs_read(gs_title("PA"))
head(PA)
```

Check ADDRESS2

```{r, address2}
PA %>% filter(!is.na(ADDRESS2)) %>% select(ADDRESS, ADDRESS2)
PA %>% distinct(County)
```

All PA are SNAP, set SNAP = 1. 

```{r, makepa}
PA <- dat1 %>% 
  bind_rows(PA %>% filter(County %in% "ALLEGHENY") %>% 
              mutate(address = ifelse(is.na(ADDRESS2), ADDRESS, paste(ADDRESS, ADDRESS2)), 
                     SNAP = 1) %>% 
              select(name = STORE_NAME, 
                          longitude,
                          latitude, 
                          address, # check linking together is correct
                          city = CITY,
                          state = STATE, 
                          zip_code = ZIP5))

write_excel_csv(PA, "PA_ALLEGHENY_cleaned.csv")

```

**Check if should filter beyond Allegheny county; missing open day/time and SNAP etc info**

### pfpc - fresh corners

```{r}
pfpc_fresh_corners <- gs_read(gs_title("PFPC Member Datasets"), ws = "Just Harvest - Fresh Corners Stores")
head(pfpc_fresh_corners)
```

Assume type = "Convenience Store"

```{r}
# dat1 %>% names()
pfpc_fresh_corners <- dat1 %>% 
  bind_rows(pfpc_fresh_corners %>% 
              mutate(food_bucks = ifelse(`Participates in Food Bucks SNAP Incentive Program` %in% "yes", 
                                         1, 0),
                     type = "Convenience Store") %>% 
              select(name = `Corner Store`,
                     address = Address,
                     city = City,
                     zip_code = Zip,
                     food_bucks,
                     type))

write_excel_csv(pfpc_fresh_corners, "pfpc_fresh_corners_cleaned.csv")
```

## pfpc - fresh access markets

Assume type = "Farmers Market"

```{r}
pfpc_fresh_access_markets <- gs_read(gs_title("PFPC Member Datasets"), ws = "Just Harvest - Fresh Access Markets")

head(pfpc_fresh_access_markets)
```

assume type = "Farmers Market"

```{r}
pfpc_fresh_access_markets <- dat1 %>% 
  bind_rows(pfpc_fresh_access_markets %>% 
              mutate(uid = 1:n(),
                     date_from = str_split(Season, "-")[[1]][1],
                     date_to = str_split(Season, "-")[[1]][2],
                     food_bucks = ifelse(`Participates in Food Bucks SNAP Incentive program` %in% "yes", 1, 0),
                     type = "Farmers Market") %>% 
              select(uid,
                     name = Market,
                     address,
                     street_one,
                     street_two,
                     city,
                     state,
                     zip_code,
                     date_from,
                     date_to,
                     open_time1, 
                     close_time1, 
                     location_description = description,
                     food_bucks) %>% 
              left_join(pfpc_fresh_access_markets %>% 
                          mutate(uid = 1:n(), fill_val = 1) %>% 
                          select(uid, fill_val, weekday) %>% 
                          tidyr::spread(key = "weekday", value = "fill_val"),
                        by = "uid") %>% 
              select(-uid))

write_excel_csv(pfpc_fresh_access_markets, "pfpc_fresh_market_cleaned.csv")
              
```


## pfpc green grocer


```{r}
pfpc_green_grocer <- gs_read(gs_title("PFPC Member Datasets"), ws = "GPCFB - Green Grocer")

head(pfpc_green_grocer)
```


```{r}
pfpc_green_grocer <- dat1 %>% 
  bind_rows(pfpc_green_grocer %>% 
              mutate(uid = 1:n(), 
                     open_time1 = str_split(str_split(`Date/Time`, "\n")[[1]][2], "-")[[1]][1],
                     close_time1 = str_split(str_split(`Date/Time`, "\n")[[1]][2], "-")[[1]][2],
                     food_bucks = ifelse(`Participates in Food Bucks SNAP Incentive Program` %in% "yes", 1, 0),
                     name = paste0("Green Grocer ", "(", name, ")")) %>% 
              select(name, 
                     address, 
                     city, 
                     state, 
                     zip_code, 
                     street_one, 
                     street_two, 
                     location_description = Description,
                     open_time1, 
                     close_time1, 
                     food_bucks,
                     uid) %>% 
                left_join(pfpc_green_grocer %>% 
                            mutate(uid = 1:n(), fill_val = 1) %>% 
                            rowwise() %>% 
                            mutate(day = str_trim(str_split(`Date/Time`, "\n")[[1]][1])) %>% 
                            select(uid, day, fill_val) %>% tidyr::spread(key = "day", value = "fill_val"),
                          by = "uid") %>% 
              select(-uid))


write_excel_csv(pfpc_green_grocer, "pfpc_fresh_green_grocer_cleaned.csv")

```

## pfpc - additional food bucks

```{r}
pfpc_more_food_bucks <- gs_read(gs_title("PFPC Member Datasets"), ws = "Additional Food Bucks sites")

pfpc_more_food_bucks <- pfpc_more_food_bucks %>% slice(1:3)

head(pfpc_more_food_bucks)
```


```{r}
pfpc_more_food_bucks <- dat1 %>% 
  bind_rows(pfpc_more_food_bucks %>% 
              mutate(food_bucks = 1) %>% 
              select(name = Name, 
                     address = Address, 
                     city, 
                     state,
                     zip_code,
                     food_bucks))

write_excel_csv(pfpc_more_food_bucks, "pfpc_fresh_more_food_bucks_cleaned.csv")

```


## updated 2019 summer food sites

From USDA site, updates weekly on Wednesdays, has API (this is currently using static .csv). 

```{r}
## read in
summer_site_2019 <- read_csv("../Summer_Meal_Sites_2019.csv")
max_NA <- function(x) ifelse( !all(is.na(x)), max(x, na.rm=T), NA)
```

```{r}
## filter to PA, Allegeheny, status = Open
summer_site_2019 <- summer_site_2019 %>% filter(siteState %in% "PA", County %in% "Allegheny", siteStatus %in% "Open")
```

```{r}
## fit to data model

summer_site_2019 <- dat1 %>% 
  bind_rows(summer_site_2019 %>% 
              rowwise() %>% 
              mutate(type = "Summer Food Site",
                     address = str_split(siteAddress, "[:alpha:]*,")[[1]][1], 
                     open_to_spec_group = 1) %>% 
              ungroup() %>% 
              select(name = siteName,
                     type, 
                     address,
                     city = siteCity,
                     state = siteState,
                     zip_code = siteZip,
                     date_from = startDate,
                     date_to = endDate,
                     latitude = Y,
                     longitude = X,
                     OBJECTID,
                     open_to_spec_group) %>% 
                left_join(summer_site_2019 %>% select(OBJECTID, daysofOperation) %>%
                            tidyr::separate(daysofOperation, sep = ",", 
                                            into = c("X1", "X2", "X3", "X4", "X5", "X6", "X7")) %>% 
                            tidyr::gather(key = "key", value = "value", -OBJECTID) %>% 
                            filter(!is.na(value)) %>% 
                            mutate(value2 = ifelse(value %in% "M", "Monday", NA),
                                   value2 = ifelse(value %in% "T", "Tuesday", value2),
                                   value2 = ifelse(value %in% "W", "Wednesday", value2),
                                   value2 = ifelse(value %in% "TH", "Thursday", value2),
                                   value2 = ifelse(value %in% "F", "Friday", value2),
                                   value2 = ifelse(value %in% "SA", "Saturday", value2),
                                   value2 = ifelse(value %in% "S", "Sunday", value2)) %>% 
                            mutate(value3 = 1) %>% 
                            tidyr::spread(key = "value2", value = "value3") %>% 
                            select(OBJECTID, Monday, Tuesday, Wednesday, Thursday,
                                   Friday, Saturday, Sunday) %>%
                            group_by(OBJECTID) %>%
                            summarise_all(max_NA),
                          by = "OBJECTID") %>% 
              left_join(summer_site_2019 %>% 
                          select(OBJECTID, contains("Time")) %>% 
                          tidyr::gather(key = "key", value = "value", -OBJECTID) %>% 
                          filter(!is.na(value)) %>% 
                          group_by(OBJECTID) %>% mutate(timing = paste0("time", 1:n())) %>% 
                          select(-key) %>% 
                          tidyr::spread(key = "timing", value = "value") %>% 
                          mutate(open_time1 = str_split(time1, " ")[[1]][1],
                                 close_time1 = str_split(time1, " ")[[1]][3],
                                 open_time2 = str_split(time2, " ")[[1]][1],
                                 close_time2 = str_split(time2, " ")[[1]][3]) %>% 
                          select(-time1, -time2), 
                        by = "OBJECTID") %>% 
              select(-OBJECTID))
```

```{r}
## write out 
write_excel_csv(summer_site_2019, "agh_summer_sites_cleaned.csv")
```
